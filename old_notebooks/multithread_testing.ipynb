{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0542e2e-d095-41f9-85d2-957df47969a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9761d7b9-39ee-4ceb-91c5-08d6d46e6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls():\n",
    "    \"\"\" Historic list of urls we're scraping from as well as the current one. Needs to be changed when a new thread\n",
    "    is made\"\"\"\n",
    "\n",
    "    url_list = [\n",
    "        'https://www.mumsnet.com/talk/am_i_being_unreasonable/4676538-if-you-like-wordle-plusword-is-even-better-thread-4?page=',\n",
    "        #'https://www.mumsnet.com/talk/_chat/4714295-plusword-new-thread-1?page=',\n",
    "        #'https://www.mumsnet.com/talk/_chat/4765702-plusword-new-thread-2?page='\n",
    "    ]\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028aced1-c47c-4316-b203-010c92ed904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_generator():\n",
    "    \n",
    "    url_list = []\n",
    "\n",
    "    thread_list = [\n",
    "        #'https://www.mumsnet.com/talk/am_i_being_unreasonable/4676538-if-you-like-wordle-plusword-is-even-better-thread-4?page=',\n",
    "        #'https://www.mumsnet.com/talk/_chat/4714295-plusword-new-thread-1?page=',\n",
    "        'https://www.mumsnet.com/talk/_chat/4765702-plusword-new-thread-2?page=1']\n",
    "\n",
    "    for thread in thread_list:\n",
    "        for page_number in range(1,41):\n",
    "            page_url = thread + str(page_number)\n",
    "            url_list.append(page_url)\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1353a2db-f1c9-4f87-8817-af7b22a38254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_to_text_converter(post,\n",
    "                           #whole_post_list\n",
    "                          ):\n",
    "    \n",
    "    # converts to list and removes whitespace\n",
    "    post_text = post.getText().split()\n",
    "    \n",
    "    # separates out meta data and post body\n",
    "    meta_data = post_text[:4]\n",
    "    post_body = post_text[4:]\n",
    "    \n",
    "    # removes fullstop from meta data\n",
    "    meta_data.pop(1)\n",
    "    \n",
    "    # converts whole of post body to one string\n",
    "    post_body = ' '.join(post_body)\n",
    "    meta_data.append(post_body)\n",
    "    whole_post = meta_data\n",
    "    #whole_post_list.append(whole_post)\n",
    "    \n",
    "    return whole_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c20d80f-8b7d-4803-bcb6-7184790493bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_scraper(url_list):\n",
    "    \"\"\" Loops over all the different types of posts on the mumsnet website, accessing the text values. Then appends\n",
    "    them to a list which is finally converted to a dataframe and returned\"\"\"\n",
    "\n",
    "    whole_post_list = []\n",
    "\n",
    "    # maximum number of pages in thread\n",
    "    max_pages = 41\n",
    "\n",
    "    # html class of original post from the thread\n",
    "    first_post_class = 'p-4 pb-1 pt-2.5 lg:py-2.5 mt-2.5 lg:mt-1.5 border-t border-b sm:border sm:rounded ' \\\n",
    "                       'border-mumsnet-forest-border bg-mumsnet-forest dark:bg-mumsnet-forest-dark'\n",
    "\n",
    "    # html class of a normal post from the thread\n",
    "    normal_reply_class = 'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 overflow-x-hidden ' \\\n",
    "                         'bg-white dark:bg-gray-800 border-gray-200'\n",
    "\n",
    "    # html class of a post from the thread creator\n",
    "    original_poster_reply_class = 'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 ' \\\n",
    "                                  'overflow-x-hidden bg-mumsnet-forest dark:bg-mumsnet-forest-dark ' \\\n",
    "                                  'border-mumsnet-forest-border'\n",
    "\n",
    "    for url in url_list:\n",
    "\n",
    "        # Increments through every page on website until it runs out for hits max_pages\n",
    "        for page_number in range(max_pages):\n",
    "\n",
    "            try:\n",
    "\n",
    "                # gets request via bs4\n",
    "                r = requests.get(url + str(page_number))\n",
    "                soup = BeautifulSoup(r.content, features=\"html5lib\")\n",
    "                \n",
    "                # Finds original post on first page and splits it into metadata and post text\n",
    "                original_post = soup.find_all('div', class_=first_post_class)\n",
    "                original_post_paragraphs = original_post[0].find_all('p')\n",
    "                original_post = soup.find_all('div', class_=original_post_class)\n",
    "                original_post = original_post[0].find_all('div', class_='')\n",
    "\n",
    "                # converts to list\n",
    "                meta_data = original_post_paragraphs[0].getText().split()\n",
    "\n",
    "                # removes fullstops in position 1\n",
    "                meta_data.pop(1)\n",
    "\n",
    "                # converts text to list and then joins items together\n",
    "                post_text = original_post_paragraphs[1].getText().split()\n",
    "                post_text = ' '.join(post_text)\n",
    "\n",
    "                # Adds OP metadata and text together and adds together for OP on every page\n",
    "                meta_data.append(post_text)\n",
    "                whole_post = meta_data\n",
    "                whole_post_list.append(whole_post)\n",
    "\n",
    "                # finds all non-OP post on page and gets data\n",
    "                posts = soup.find_all('div', class_=[normal_reply_class, original_poster_reply_class])\n",
    "\n",
    "                for post in posts:\n",
    "                    post_info = post.getText().split()\n",
    "\n",
    "                    # first 4 items are meta data\n",
    "                    meta_data = post_info[:4]\n",
    "\n",
    "                    # removes unneeded full stop\n",
    "                    meta_data.pop(1)\n",
    "\n",
    "                    # joins post text together\n",
    "                    post_text = post_info[4:]\n",
    "                    post_text = ' '.join(post_text)\n",
    "\n",
    "                    # appends metadata and text together and adds to list\n",
    "                    meta_data.append(post_text)\n",
    "                    whole_post = meta_data\n",
    "                    whole_post_list.append(whole_post)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(whole_post_list, columns=['user', 'date', 'time', 'text'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596820b5-9f1b-4d0a-9219-a7f4a36a856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_scraper(url):\n",
    "\n",
    "    whole_post_list = []\n",
    "\n",
    "    # maximum number of pages in thread\n",
    "    max_pages = 41\n",
    "\n",
    "    # html class of original post from the thread\n",
    "    original_post_class = 'p-4 pb-1 pt-2.5 lg:py-2.5 mt-2.5 lg:mt-1.5 border-t border-b sm:border sm:rounded ' \\\n",
    "                       'border-mumsnet-forest-border bg-mumsnet-forest dark:bg-mumsnet-forest-dark'\n",
    "\n",
    "    # html class of a normal post from the thread\n",
    "    normal_post_class = 'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 overflow-x-hidden ' \\\n",
    "                         'bg-white dark:bg-gray-800 border-gray-200'\n",
    "\n",
    "    # html class of a post from the thread creator\n",
    "    original_poster_reply_class = 'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 ' \\\n",
    "                                  'overflow-x-hidden bg-mumsnet-forest dark:bg-mumsnet-forest-dark ' \\\n",
    "                                  'border-mumsnet-forest-border'\n",
    "\n",
    "    # gets request via bs4\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, features=\"html5lib\")\n",
    "\n",
    "    try:\n",
    "        if url[-1] == str(1) :\n",
    "\n",
    "            # Finds original post on first page and splits it into metadata and post text\n",
    "            original_post = soup.find_all('div', class_=original_post_class)\n",
    "            original_post = original_post[0].find_all('div', class_='')\n",
    "\n",
    "            whole_post=post_to_text_converter(original_post[2], whole_post_list)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # finds all non-OP post on page and gets data\n",
    "    posts = soup.find_all('div', class_=[normal_post_class, original_poster_reply_class])\n",
    "\n",
    "    for post in posts:\n",
    "        whole_post = post_to_text_converter(post)\n",
    "\n",
    "    return whole_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29514e0-2fd5-4de3-98fc-e5583d00a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multithread_wrapper(url_list):\n",
    "    \n",
    "    #url_list = url_generator()\n",
    "    #url = 'https://www.mumsnet.com/talk/_chat/4765702-plusword-new-thread-2?page=1'\n",
    "    \n",
    "    result_list = []\n",
    "\n",
    "    # maximum number of pages in thread\n",
    "    max_pages = 41\n",
    "\n",
    "    # html class of original post from the thread\n",
    "    original_post_class = 'p-4 pb-1 pt-2.5 lg:py-2.5 mt-2.5 lg:mt-1.5 border-t border-b sm:border sm:rounded ' \\\n",
    "                       'border-mumsnet-forest-border bg-mumsnet-forest dark:bg-mumsnet-forest-dark'\n",
    "\n",
    "    # html class of a normal post from the thread\n",
    "    normal_post_class = 'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 overflow-x-hidden ' \\\n",
    "                         'bg-white dark:bg-gray-800 border-gray-200'\n",
    "\n",
    "    # html class of a post from the thread creator\n",
    "    original_poster_reply_class = 'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 ' \\\n",
    "                                  'overflow-x-hidden bg-mumsnet-forest dark:bg-mumsnet-forest-dark ' \\\n",
    "                                  'border-mumsnet-forest-border'\n",
    "\n",
    "    # gets request via bs4\n",
    "    \n",
    "    for url in url_list:\n",
    "    \n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, features=\"html5lib\")\n",
    "\n",
    "    #     if url[-1] == str(1) :\n",
    "\n",
    "    #         # Finds original post on first page and splits it into metadata and post text\n",
    "    #         original_post = soup.find_all('div', class_=original_post_class)\n",
    "    #         original_post = original_post[0].find_all('div', class_='')\n",
    "\n",
    "    #         whole_post=post_to_text_converter(original_post[2], whole_post_list)\n",
    "\n",
    "\n",
    "        # finds all non-OP post on page and gets data\n",
    "        posts = soup.find_all('div', class_=[normal_post_class, original_poster_reply_class])\n",
    "\n",
    "        # for post in posts:\n",
    "        #     whole_post = post_to_text_converter(post)\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            results = executor.map(post_to_text_converter, posts)\n",
    "            for result in results:\n",
    "                result_list.append(result)\n",
    "    \n",
    "    df = pd.DataFrame(result_list, columns=['user', 'date', 'time', 'text'])\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928fb6f0-14bd-4c8f-bfa6-70554bab71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_start = time.time()\n",
    "url_list = get_urls()\n",
    "original_df = original_scraper(url_list)\n",
    "original_end = time.time()\n",
    "original_time = original_end - original_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c12b992-5290-4bf5-bf8f-3726e80f646a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.094024419784546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee3835-88be-43f9-ab54-278bfb9d8209",
   "metadata": {
    "tags": []
   },
   "source": [
    "url_list = get_urls()\n",
    "modified_start = time.time()\n",
    "modified_df = modified_scraper(url_list)\n",
    "modified_end = time.time()\n",
    "modified_time = modified_end - modified_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9172b749-80c9-4452-8e88-63c507a2c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_start = time.time()\n",
    "url_list = url_generator()\n",
    "modified_df = multithread_wrapper(url_list)\n",
    "modified_end = time.time()\n",
    "modified_time = modified_end - modified_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3c2c32-091a-4c76-834a-fdebfa6951a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.3880181312561"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a959b8dc-85f6-427a-9867-6dac20752984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILoveAllRainbowsx</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>14:18</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/am_i_bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Floralnomad</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>15:57</td>\n",
       "      <td>Thanks for this @ILoveAllRainbowsx Add message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>16:08</td>\n",
       "      <td>Thanks @ILoveAllRainbowsx - hopefully thread 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Readytostartagain</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>16:25</td>\n",
       "      <td>Thanks for this @ILoveAllRainbowsx . Did CW in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hepzibar</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>16:25</td>\n",
       "      <td>Thanks for the new thread and reminder @ILoveA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Readytostartagain</td>\n",
       "      <td>14/11/2022</td>\n",
       "      <td>08:07</td>\n",
       "      <td>1:42 today much easier than yesterday üòÉ Add me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>UmbilicusProfundus</td>\n",
       "      <td>14/11/2022</td>\n",
       "      <td>08:09</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 01:16 slow sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>MarmiteWine</td>\n",
       "      <td>14/11/2022</td>\n",
       "      <td>08:14</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 00:52 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>BrilliantGreenFlamingo</td>\n",
       "      <td>14/11/2022</td>\n",
       "      <td>11:57</td>\n",
       "      <td>6:19 today. Got a word wrong which threw me fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>LikeTearsInRain</td>\n",
       "      <td>15/11/2022</td>\n",
       "      <td>00:27</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 05:30 Had to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user        date   time  \\\n",
       "0         ILoveAllRainbowsx  13/11/2022  14:18   \n",
       "1               Floralnomad  13/11/2022  15:57   \n",
       "2    Drywhitefruitycidergin  13/11/2022  16:08   \n",
       "3         Readytostartagain  13/11/2022  16:25   \n",
       "4                  Hepzibar  13/11/2022  16:25   \n",
       "..                      ...         ...    ...   \n",
       "986       Readytostartagain  14/11/2022  08:07   \n",
       "987      UmbilicusProfundus  14/11/2022  08:09   \n",
       "988             MarmiteWine  14/11/2022  08:14   \n",
       "989  BrilliantGreenFlamingo  14/11/2022  11:57   \n",
       "990         LikeTearsInRain  15/11/2022  00:27   \n",
       "\n",
       "                                                  text  \n",
       "0    Previous thread: www.mumsnet.com/talk/am_i_bei...  \n",
       "1    Thanks for this @ILoveAllRainbowsx Add message...  \n",
       "2    Thanks @ILoveAllRainbowsx - hopefully thread 4...  \n",
       "3    Thanks for this @ILoveAllRainbowsx . Did CW in...  \n",
       "4    Thanks for the new thread and reminder @ILoveA...  \n",
       "..                                                 ...  \n",
       "986  1:42 today much easier than yesterday üòÉ Add me...  \n",
       "987  ‚è±Ô∏è I just completed PlusWord in 01:16 slow sta...  \n",
       "988  ‚è±Ô∏è I just completed PlusWord in 00:52 www.tele...  \n",
       "989  6:19 today. Got a word wrong which threw me fo...  \n",
       "990  ‚è±Ô∏è I just completed PlusWord in 05:30 Had to l...  \n",
       "\n",
       "[991 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab49838-f465-4b2f-ac16-26c41669063b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IGoWalkingAfterMidnight</td>\n",
       "      <td>10/04/2023</td>\n",
       "      <td>10:24</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 01:39 Add mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hoochycrone</td>\n",
       "      <td>10/04/2023</td>\n",
       "      <td>16:38</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 01:45 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MarmiteWine</td>\n",
       "      <td>10/04/2023</td>\n",
       "      <td>18:48</td>\n",
       "      <td>00:44 here. Misspelled 7A at first attempt and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>11/04/2023</td>\n",
       "      <td>00:15</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 02:04 Grrrrr t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunbird24</td>\n",
       "      <td>11/04/2023</td>\n",
       "      <td>00:44</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 00:48 OP posts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>sanityisamyth</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>05:44</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 01:03 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>06:24</td>\n",
       "      <td>‚è±Ô∏è I just completed PlusWord in 04:04 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>DadDadDad</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>07:04</td>\n",
       "      <td>1:27 for me today. Add message Save Share Repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Madcats</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>09:40</td>\n",
       "      <td>It took me a while to understand the answer to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>PlusWordImogen</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>10:50</td>\n",
       "      <td>Hi all! I work on the Puzzles team at the Tele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user        date   time  \\\n",
       "0    IGoWalkingAfterMidnight  10/04/2023  10:24   \n",
       "1                hoochycrone  10/04/2023  16:38   \n",
       "2                MarmiteWine  10/04/2023  18:48   \n",
       "3     Drywhitefruitycidergin  11/04/2023  00:15   \n",
       "4                  Sunbird24  11/04/2023  00:44   \n",
       "..                       ...         ...    ...   \n",
       "975            sanityisamyth  21/03/2023  05:44   \n",
       "976   Drywhitefruitycidergin  21/03/2023  06:24   \n",
       "977                DadDadDad  21/03/2023  07:04   \n",
       "978                  Madcats  21/03/2023  09:40   \n",
       "979           PlusWordImogen  21/03/2023  10:50   \n",
       "\n",
       "                                                  text  \n",
       "0    ‚è±Ô∏è I just completed PlusWord in 01:39 Add mess...  \n",
       "1    ‚è±Ô∏è I just completed PlusWord in 01:45 www.tele...  \n",
       "2    00:44 here. Misspelled 7A at first attempt and...  \n",
       "3    ‚è±Ô∏è I just completed PlusWord in 02:04 Grrrrr t...  \n",
       "4    ‚è±Ô∏è I just completed PlusWord in 00:48 OP posts...  \n",
       "..                                                 ...  \n",
       "975  ‚è±Ô∏è I just completed PlusWord in 01:03 www.tele...  \n",
       "976  ‚è±Ô∏è I just completed PlusWord in 04:04 www.tele...  \n",
       "977  1:27 for me today. Add message Save Share Repo...  \n",
       "978  It took me a while to understand the answer to...  \n",
       "979  Hi all! I work on the Puzzles team at the Tele...  \n",
       "\n",
       "[980 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e9cf7-4584-48ac-9332-00bdb0dc969c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
