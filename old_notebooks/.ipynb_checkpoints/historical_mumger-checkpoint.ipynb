{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c84ad7-9fe9-4395-8f58-8da283b95747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%cache magic is now registered in ipython\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime as dt\n",
    "import cache_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3ffa0-5926-4fc1-a28a-2d08514bf63a",
   "metadata": {},
   "source": [
    "### List of mumsnet urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6d43bd-616b-487f-9a52-434664ab1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['https://www.mumsnet.com/talk/am_i_being_unreasonable/4676538-if-you-like-wordle-plusword-is-even-better-thread-4?page=',\n",
    "            'https://www.mumsnet.com/talk/_chat/4714295-plusword-new-thread-1?page=',\n",
    "            'https://www.mumsnet.com/talk/_chat/4765702-plusword-new-thread-2?page=']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89af20-4cd1-445a-99d2-34e7e28467b8",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36faf4d3-ff7e-4884-8620-7706df28f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url, max_pages, whole_post_list):\n",
    "    \n",
    "    # Increments through every page on website until it runs out for hits max_pages\n",
    "    for page_number in range(max_pages):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # gets request via bs4\n",
    "            r = requests.get(url + str(page_number))\n",
    "            soup = BeautifulSoup(r.content)\n",
    "            \n",
    "            # Finds original post on each page and splits it into metadata and post text\n",
    "            original_post = soup.find_all('div', class_= 'p-4 pb-1 pt-2.5 lg:py-2.5 mt-2.5 lg:mt-1.5 border-t border-b sm:border sm:rounded border-mumsnet-forest-border bg-mumsnet-forest dark:bg-mumsnet-forest-dark')\n",
    "            original_post_paragraphs=original_post[0].find_all('p')\n",
    "            \n",
    "            # converts to list\n",
    "            meta_data = original_post_paragraphs[0].getText().split()\n",
    "            \n",
    "            # removes fullstop in position 1\n",
    "            meta_data.pop(1)\n",
    "            \n",
    "            # converts text to list and then joins items together\n",
    "            post_text = original_post_paragraphs[1].getText().split()\n",
    "            post_text =' '.join(post_text)\n",
    "            \n",
    "            # Adds OP metadata and text together and adds together for OP on every page\n",
    "            meta_data.append(post_text)\n",
    "            whole_post = meta_data\n",
    "            whole_post_list.append(whole_post)\n",
    "            \n",
    "            # finds all non-OP post on page and gets data\n",
    "            posts= soup.find_all('div', class_='lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 overflow-x-hidden bg-white dark:bg-gray-800 border-gray-200')\n",
    "            for post in posts:\n",
    "                post_info = post.getText().split()\n",
    "                \n",
    "                #first 4 items are meta data\n",
    "                meta_data = post_info[:4]\n",
    "                \n",
    "                #removes uneeded full stop\n",
    "                meta_data.pop(1)\n",
    "                \n",
    "               # joins post text together\n",
    "                post_text = post_info[4:]\n",
    "                post_text = ' '.join(post_text)\n",
    "                \n",
    "                \n",
    "                # appends metadata and text together and adds to list\n",
    "                meta_data.append(post_text)\n",
    "                whole_post = meta_data\n",
    "                whole_post_list.append(whole_post)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return whole_post_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2c62c-21ae-41dd-abfe-e31a4cc01b08",
   "metadata": {},
   "source": [
    "## Scraper initialization and df generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ccb6c5-607b-4685-ba22-4739129f9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_post_list=[]\n",
    "\n",
    "# maxiumum number of pages in thread\n",
    "max_posts = 41\n",
    "\n",
    "for url in url_list:\n",
    "\n",
    "    whole_post_list = scraper(url, max_posts, whole_post_list)\n",
    "            \n",
    "df = pd.DataFrame(whole_post_list, columns=['user', 'date', 'time', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7104a-9f1b-4b66-987f-4bc4a19aff4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converts 'Today' and 'Yesterday to date values, creates and sorts by timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5584b88b-4419-47cb-9731-d25d46ef190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILoveAllRainbowsx</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>14:18</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/am_i_bei...</td>\n",
       "      <td>2022-11-13 14:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>ILoveAllRainbowsx</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>14:18</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/am_i_bei...</td>\n",
       "      <td>2022-11-13 14:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>ILoveAllRainbowsx</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>14:18</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/am_i_bei...</td>\n",
       "      <td>2022-11-13 14:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>ILoveAllRainbowsx</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>14:18</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/am_i_bei...</td>\n",
       "      <td>2022-11-13 14:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>ILoveAllRainbowsx</td>\n",
       "      <td>13/11/2022</td>\n",
       "      <td>14:18</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/am_i_bei...</td>\n",
       "      <td>2022-11-13 14:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>Floralnomad</td>\n",
       "      <td>17/04/2023</td>\n",
       "      <td>01:30</td>\n",
       "      <td>00:54 nice one today Add message Save Share Re...</td>\n",
       "      <td>2023-04-17 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>DadDadDad</td>\n",
       "      <td>17/04/2023</td>\n",
       "      <td>07:08</td>\n",
       "      <td>1:27 for me. Took a while to get started on th...</td>\n",
       "      <td>2023-04-17 07:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>Albaniarocks</td>\n",
       "      <td>17/04/2023</td>\n",
       "      <td>07:21</td>\n",
       "      <td>⏱️ I just completed PlusWord in 00:52 www.tele...</td>\n",
       "      <td>2023-04-17 07:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>JoyDivisionOvenGlovesx</td>\n",
       "      <td>17/04/2023</td>\n",
       "      <td>07:41</td>\n",
       "      <td>⏱️ I just completed PlusWord in 01:12 Another ...</td>\n",
       "      <td>2023-04-17 07:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>Readytostartagain</td>\n",
       "      <td>17/04/2023</td>\n",
       "      <td>13:53</td>\n",
       "      <td>⏱️ I just completed PlusWord in 00:59 Add mess...</td>\n",
       "      <td>2023-04-17 13:53:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2909 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user        date   time  \\\n",
       "0          ILoveAllRainbowsx  13/11/2022  14:18   \n",
       "436        ILoveAllRainbowsx  13/11/2022  14:18   \n",
       "412        ILoveAllRainbowsx  13/11/2022  14:18   \n",
       "847        ILoveAllRainbowsx  13/11/2022  14:18   \n",
       "389        ILoveAllRainbowsx  13/11/2022  14:18   \n",
       "...                      ...         ...    ...   \n",
       "2279             Floralnomad  17/04/2023  01:30   \n",
       "2281               DadDadDad  17/04/2023  07:08   \n",
       "2282            Albaniarocks  17/04/2023  07:21   \n",
       "2283  JoyDivisionOvenGlovesx  17/04/2023  07:41   \n",
       "2284       Readytostartagain  17/04/2023  13:53   \n",
       "\n",
       "                                                   text           timestamp  \n",
       "0     Previous thread: www.mumsnet.com/talk/am_i_bei... 2022-11-13 14:18:00  \n",
       "436   Previous thread: www.mumsnet.com/talk/am_i_bei... 2022-11-13 14:18:00  \n",
       "412   Previous thread: www.mumsnet.com/talk/am_i_bei... 2022-11-13 14:18:00  \n",
       "847   Previous thread: www.mumsnet.com/talk/am_i_bei... 2022-11-13 14:18:00  \n",
       "389   Previous thread: www.mumsnet.com/talk/am_i_bei... 2022-11-13 14:18:00  \n",
       "...                                                 ...                 ...  \n",
       "2279  00:54 nice one today Add message Save Share Re... 2023-04-17 01:30:00  \n",
       "2281  1:27 for me. Took a while to get started on th... 2023-04-17 07:08:00  \n",
       "2282  ⏱️ I just completed PlusWord in 00:52 www.tele... 2023-04-17 07:21:00  \n",
       "2283  ⏱️ I just completed PlusWord in 01:12 Another ... 2023-04-17 07:41:00  \n",
       "2284  ⏱️ I just completed PlusWord in 00:59 Add mess... 2023-04-17 13:53:00  \n",
       "\n",
       "[2909 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = df['date'].str.replace('Yesterday', dt.datetime.strftime((dt.datetime.today() - dt.timedelta(days=1)), '%d/%m/%Y'))\n",
    "df['date'] = df['date'].str.replace('Today', dt.datetime.strftime(dt.datetime.today(), '%d/%m/%Y'))\n",
    "df['timestamp'] = pd.to_datetime(df['date'] + ' ' + (df['time']+':00'), format='%d/%m/%Y %H:%M:%S')\n",
    "df = df.sort_values(by=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4216210-d8d4-4408-b017-32bdbf1fd74e",
   "metadata": {},
   "source": [
    "### Extracts times from text and adds 00: to allow it to handle hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e2efb6-5742-41ba-8b3e-76e9bd47755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] =df['text'].str.extract(r'(\\d*\\d:\\d\\d)')\n",
    "df = df.dropna(subset='text')\n",
    "df = df.copy()\n",
    "df['text'] =df['text'].str.replace(r'(^\\d:\\d\\d)', r'0\\1', regex=True)\n",
    "df['text'] = '00:' + df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcc181-ee50-459a-b718-16b82b91c9b8",
   "metadata": {},
   "source": [
    "### Drops duplicate entries for users on same date, drops columns and renames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b789493-e469-4e54-a415-30f581528120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df= df.drop_duplicates(subset=['user', 'date'])\n",
    "df = df.drop(columns=['date', 'time'])\n",
    "df = df.rename(columns={'text' : 'time'})\n",
    "df = df[['timestamp', 'user', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76208623-f5e9-49cc-8b43-26f2e789b00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>2022-11-13 17:05:00</td>\n",
       "      <td>BrilliantGreenFlamingo</td>\n",
       "      <td>00:04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>2022-11-13 17:20:00</td>\n",
       "      <td>MarmiteWine</td>\n",
       "      <td>00:01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-11-14 00:09:00</td>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>00:02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>2022-11-14 00:51:00</td>\n",
       "      <td>Floralnomad</td>\n",
       "      <td>00:01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-11-14 02:48:00</td>\n",
       "      <td>Sunbird24</td>\n",
       "      <td>00:00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>2023-04-17 01:30:00</td>\n",
       "      <td>Floralnomad</td>\n",
       "      <td>00:00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>2023-04-17 07:08:00</td>\n",
       "      <td>DadDadDad</td>\n",
       "      <td>00:01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>2023-04-17 07:21:00</td>\n",
       "      <td>Albaniarocks</td>\n",
       "      <td>00:00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>2023-04-17 07:41:00</td>\n",
       "      <td>JoyDivisionOvenGlovesx</td>\n",
       "      <td>00:01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2023-04-17 13:53:00</td>\n",
       "      <td>Readytostartagain</td>\n",
       "      <td>00:00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1670 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp                    user      time\n",
       "949  2022-11-13 17:05:00  BrilliantGreenFlamingo  00:04:03\n",
       "925  2022-11-13 17:20:00             MarmiteWine  00:01:41\n",
       "39   2022-11-14 00:09:00  Drywhitefruitycidergin  00:02:19\n",
       "956  2022-11-14 00:51:00             Floralnomad  00:01:21\n",
       "16   2022-11-14 02:48:00               Sunbird24  00:00:53\n",
       "...                  ...                     ...       ...\n",
       "2279 2023-04-17 01:30:00             Floralnomad  00:00:54\n",
       "2281 2023-04-17 07:08:00               DadDadDad  00:01:27\n",
       "2282 2023-04-17 07:21:00            Albaniarocks  00:00:52\n",
       "2283 2023-04-17 07:41:00  JoyDivisionOvenGlovesx  00:01:12\n",
       "2284 2023-04-17 13:53:00       Readytostartagain  00:00:59\n",
       "\n",
       "[1670 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cf866-6c26-4f15-8912-01d96494d425",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prints timestamped csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca8456c-fa5c-446b-b372-65ed65bba990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/historical_mumsnet_data_' + str(dt.datetime.now()) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
